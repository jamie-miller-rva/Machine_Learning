{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Ins_Quantifying_Regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamie-miller-rva/Machine_Learning/blob/main/Ins_Quantifying_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojg3vFLFq-OH"
      },
      "source": [
        "# Quantifying Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXPfw_qKq-OP"
      },
      "source": [
        "Create a model to quantify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abo-Pshyq-OR",
        "outputId": "21af488e-894a-46f0-9634-a9729e6f3437"
      },
      "source": [
        "# Import dependencies\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Generate some data\n",
        "X, y = make_regression(n_samples=20, n_features=1, random_state=0, noise=4, bias=100.0)\n",
        "\n",
        "# Create a linear model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit (Train) our model to the data\n",
        "model.fit(X, y)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72qBV8nLq-OU"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1YFzKKKq-OV"
      },
      "source": [
        "## Quantifying our Model\n",
        "\n",
        "* Mean Squared Error (MSE)\n",
        "\n",
        "* R2 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJT3C2ckq-OX"
      },
      "source": [
        "There are a variety of ways to quantify the model, but MSE and R2 are very common"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSk4zZ7-q-OY",
        "outputId": "27705a2c-37a4-447b-db81-2bd7fe2ae986"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Use our model to predict a value\n",
        "predicted = model.predict(X)\n",
        "\n",
        "# Score the prediction with mse and r2\n",
        "mse = mean_squared_error(y, predicted)\n",
        "r2 = r2_score(y, predicted)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R2 ): {r2}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): 11.933040779746149\n",
            "R-squared (R2 ): 0.903603363418708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaBc8zcyq-Oa"
      },
      "source": [
        "A \"good\" MSE score will be close to zero while a \"good\" [R2 Score](https://en.wikipedia.org/wiki/Coefficient_of_determination) will be close to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K4gZOjxq-Ob",
        "outputId": "eeb5b4d9-faa5-4725-c89c-8f9c0e274167"
      },
      "source": [
        "# take the square root of mean squared error to get error back in original units\n",
        "RMSE = np.sqrt(mse)\n",
        "RMSE"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.45442336428906"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSdejRP3q-Oc"
      },
      "source": [
        "R2 Score is the default scoring for many of the Sklearn models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKAlgmf3q-Od",
        "outputId": "7e5ae8a7-403d-45bb-e714-0ff8556ecca4"
      },
      "source": [
        "# Overall Score for the model\n",
        "model.score(X, y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.903603363418708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEUJKHMVq-Oe"
      },
      "source": [
        "## Validation\n",
        "\n",
        "We also want to understand how well our model performs on new data. \n",
        "\n",
        "One approach for this is to split your data into a training and testing dataset.\n",
        "\n",
        "You fit (train) the model using training data, and score and validate your model using the testing data.\n",
        "\n",
        "This train/test splitting is so common that Sklearn provides a mechanism for doing this. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZI5dBnCq-Of"
      },
      "source": [
        "## Testing and Training Data\n",
        "\n",
        "In order to quantify our model against new input values, we often split the data into training and testing data. The model is then fit to the training data and scored by the test data. Sklean pre-processing provides a library for automatically splitting up the data into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEe8qwi_q-Og"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj-2vQWQq-Oh"
      },
      "source": [
        "Train the model using the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8En7WDGq-Oh",
        "outputId": "9627510b-e3ae-431b-aa3b-98a072625e0f"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keqku8zNq-Oi"
      },
      "source": [
        "And score the model using the unseen testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0hybR2Gq-Oj",
        "outputId": "6970ff50-3994-4a7d-9da8-2c7430906167"
      },
      "source": [
        "model.score(X_test, y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9252522435044104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUgAL1IJq-Oj"
      },
      "source": [
        "## Your Turn!"
      ]
    }
  ]
}